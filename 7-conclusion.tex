\chapter{Conclusion \& Future Work}

\section{Conclusion}

In this project we investigated whether transfer learning, specifically domain adaptation, can help detect political bias on social media, using knowledge learnt from detecting the same bias in news content. We started by surveying classifiers to detect bias in the news, finding SVMs and gradient-boosted forests to give the best performance, using features from earlier research. We then examined BERT models for the same task, which perform feature extraction and classification holistically, finding these also give fairly good performance.

Using our self-developed cross-domain dataset of news articles and related Reddit comments, we explored unsupervised domain adaptation techniques for detecting political bias in news and social media comments. We found classification performance when using social media comments as a predictor for news bias (\textit{comments $ \rightarrow $ articles} transfer) significantly outperforms the reverse scenario, however in both cases transfer learning cannot outperform standard in-domain classifiers. We also found that a state-of-the-art domain adaptive BERT model called AdaptaBERT outperforms direct transfer learning when optimising for the right mix of source and target domain material during training, coming very close to matching the performance of in-domain classifiers.

We investigated extending AdaptaBERT with an extra Next Sentence Prediction stage, originally used in BERT pre-training, to see if this improves classification performance. This extension yields a 3.3\% increase in F1 score for an NER task originally explored in the AdaptaBERT paper \cite{adaptabert}, however this extension also results in performance deterioration for the original political bias detection task, possibly due to the differences between the source and target domains in terms of number of sentences per sample.

Significant work still needs to be done in the field of unsupervised domain adaptation to fully match the performance of in-domain classifiers, and to see if in-domain performance can be exceeded. This would aid political bias detection on social media tremendously, where supervised domain adaptation cannot be performed due to the lack of sufficient annotated data.

\section{Ethical Issues}

With regards to data protection, our project does not involve collecting any personal data from Reddit users - all information is collected via the public Reddit API, and we immediately discard comment author information from our datasets before running our models, since we don't make use of this information in any way. An earlier project idea involved analysing the distribution of left-wing and right-wing users across various subreddits - this would involve inferring political affiliations on a per-user basis, which counts as processing `special-category' data under the UK Data Protection Act (DPA) 2018 \cite{dpa}. In this case we would need to take extra precautions when storing and processing this sensitive information.

One issue is that a third party could take our bias detectors and apply them on comments all from one social media user to determine that user's political leaning, which would of course be inferring sensitive data. This kind of privacy attack could be performed with any bias-detection machine learning model. If our model were deployed in a production environment, we could limit this kind of attack by placing our model behind a query-based interface and limiting the number of queries that can be placed.

In using Reddit comments as a predictor for political bias in the wider news context, our model may unknowingly be biased towards writing styles used by the demographics in our dataset. Reddit is known to have a mainly young, American, white and male userbase \cite{pew-reddit-demographics}, and so a bias detection classifier trained on Reddit text such as ours may start to mispredict if it comes across news or comments with writing styles different to those used by this demographic online. 

This risk is increased when using large language models such as BERT, which are pre-trained on huge amounts of data - very little is understood about the exact mechanisms BERT uses during training to ensure classification success \cite{bert-dark-secrets}. Jo \& Gebru \cite{gebru} carried out a case study on GPT-2, a large language model similar to BERT, and its pre-training corpus of Reddit data. They noted Reddit's demographics are not representative of demographics in the wider world, and due consideration of this had not been taken by the GPT-2 creators before publishing their model. We have attempted to publish significant information about our Reddit dataset in Chapter \ref{chap:reddit-data}, including which subreddits we sourced information from and how much data from each subreddit, to make our training data collection methodology more transparent.

\section{Future Work}

In this section we propose several ideas for future work that could take our research further.

\begin{itemize}
    \item \textbf{Collecting more training data}: Our cross-domain Reddit dataset is fairly small, with 806 news articles and 11,954 Reddit comments. Our research would be made much more reliable with a larger collection of news articles in our dataset, plus a wider range of politically-themed subreddits to source comments from. Many of the posts we scraped from Reddit were actually links to screenshots of news articles and tweets rather than actual articles, which we discarded - keeping these screenshots and extracting text from them would also give us access to much more Reddit training data.
    \item \textbf{Using more modern classifiers}: We chose BERT models for our experiments in Chapters \ref{chap:domain-adaptation} and \ref{chap:extending-adaptabert} since BERT performs feature extraction automatically, and still provides good classification performance for detecting political bias as seen in Chapter \ref{chap:ensemble-bert}. Newer language models, such as XLNet \cite{xlnet}, claim to improve upon BERT's performance significantly, and so assessing their performance on this political bias detection task may yield superior results.
    \item \textbf{Exploring a multi-modal approach}: Throughout this project we only examine textual content in order to detect bias. Given that much of the data we scraped from Reddit is in image format, we could build a multi-modal model that fuses information learnt from images (e.g. with a convolutional neural network) and information learnt from the text to detect bias.
    \item \textbf{Assessing non-political subreddits}: In this project we only considered politically-themed subreddits to train our classifier. Kane \& Luo \cite{kane} explored whether non-political subreddits still exhibit some unconscious political leaning, using topic modelling with Latent Dirichlet Allocation. Using our classifiers trained on political subreddit data, we could examine the same task but with a transfer learning approach, to see if our results differ from Kane \& Luo's.
    \item \textbf{A browser extension for assessing echo chambers}: An online echo chamber is an environment where a person only encounters information that reflects and reinforces their own opinions \cite{echo-chambers}. Social media users nowadays are more aware of how echo chambers can affect their point of view. By developing a browser extension that can analyse the text on screen for political bias using our classifiers, social media users can examine how the content they see on social media is politically oriented, to see if they are victim to an echo chamber.
    \item \textbf{Tackling other tasks with Next Sentence Prediction}: In this project we only examined the effect of adding Next Sentence Prediction to AdaptaBERT for political bias detection and named entity recognition tasks, both of which are classification tasks. Further work could be done exploring how Next Sentence Prediction could be utilised for domain-adaptive versions of other tasks such as question answering and natural language inference.
\end{itemize}

% Exploring bias in tabloids vs broadsheets

% Compare Reddit political scale to various countries' political scales (e.g. does it most align with the US scale?)

% Look at bias across time

% Extract word embeddings from BERT and use in SVM or other classifier, we just use BERTForSequenceClassification
