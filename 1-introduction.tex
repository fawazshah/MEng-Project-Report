\chapter{Introduction}

Political bias is being increasingly scrutinised in modern-day news media. The last decade has seen increasing political polarisation of news sources, most notably during the 2016 and 2020 US elections \cite{us-election}, even though the majority of people prefer unbiased news \cite{pew-unbiased}. As such, a big focus has been placed on detecting political bias within news content.

However, less attention has been paid to detecting the biases of readers and consumers of news. We term this \textit{readership bias}. Examining readership bias can help analysts quantify sentiment for political parties and politicians among reader communities and the general populus. Social media is a prime example of a medium where readership bias can be explored - almost 70\% of Americans now get their news from social media \cite{pew-social-media-news-2018} - and examining bias in social media comments regarding recent news can help tackle further problems on social media such as filter bubbles and echo chambers.

Most media watchdogs still perform bias detection manually \cite{mbfc} \cite{media-bias-chart}, using teams of analysts. These analysts can often only rate several dozen articles a month \cite{ad-fontes-methodology}, and may introduce their own biases into their ratings. Recent research has increasingly focused on tackling bias detection problems with machine learning and natural language processing \cite{bipartisan-press} \cite{baly-emnlp18}, which can be much faster and less susceptible to internal bias. However, while it is possible to obtain ground truth bias data for news sources from media watchdogs, obtaining annotations for individual social media comments is much more challenging.

Transfer learning is a modern field of machine learning research that takes models trained for one problem A, and `transfers' their knowledge so they can be applied for a separate, more challenging problem B. Specifically, \textit{unsupervised domain adaptation} techniques are well-suited for when there is a lack of annotated data available for problem B. In this project we seek to explore if unsupervised domain adaptation methods can be used to detect political bias in social media content, given the knowledge learnt from bias in news content. We target Reddit due to its unique features such as subreddits and upvotes/downvotes, and because a significant majority of Reddit users get their news from the site (more than both Facebook and Twitter) \cite{pew-social-media-news-2018}. Our main objectives are:

\begin{itemize}
    \item To survey existing methods for detecting political bias in the news
    \item To explore, and possibly extend, existing domain adaptation methods to improve the performance of political bias detection on social media
\end{itemize}

\section{Contributions}

The main contributions of this dissertation are as follows:

\begin{itemize}
    \item \textbf{Detecting political bias in news content} - We survey existing machine learning models for detecting political bias within news content, including ensemble classifiers that have not been explored in prior literature. We assess performance using pre-computed features from previous research, as well as using models such as BERT that perform textual feature extraction themselves (Chapter \ref{chap:ensemble-bert}).
    \item \textbf{Developing a cross-domain Reddit dataset} - We create a novel dataset consisting of both news articles and Reddit comments reacting to those articles, aimed at domain adaptation tasks. We discuss the design decisions and trade-offs involved in creating a high-quality dataset, and assess similarity between the domains in our dataset (Chapter \ref{chap:reddit-data}).
    \item \textbf{Exploring unsupervised domain adaptation techniques} - We investigate unsupervised domain adaptation methods to detect political bias on Reddit, using knowledge learnt from detecting bias in news content. We explore a direct transfer approach, and a state-of-the-art domain-adaptive BERT model called AdaptaBERT (Chapter \ref{chap:domain-adaptation}).
    \item \textbf{Extending AdaptaBERT with Next Sentence Prediction} - We extend AdaptaBERT by adding Next Sentence Prediction to its fine-tuning stages, and evaluate its performance on a political bias detection task as well as a named entity recognition (NER) task. We do not see an improvement over standard AdaptaBERT for the political bias detection task, however we see a 2.5\% improvement in F1 score for the NER task (Chapter \ref{chap:extending-adaptabert}).
\end{itemize}
