\chapter{Introduction}

Political bias is being increasingly scrutinised in modern-day news media. The last decade has seen increasing political polarisation of news sources, most notably during the 2016 and 2020 US elections \cite{us-election}, even though the vast majority of people want unbiased news \cite{pew-unbiased}. As such, a big focus has been placed on detecting political bias within news content with machine learning and natural language processing.

However, less attention has been paid to detecting the biases of readers and consumers of news. We term this \textit{readership bias}. Social media is a prime example of a medium where readership bias can be explored - almost 70\% of Americans now get their news from social media \cite{pew-social-media-news-2018}, and examining the sheer volume of comments left online from readers can help analyse the bias of readers, as well as tackle further problems on social media such as filter bubbles and echo chambers.

We employ transfer learning, specifically domain adaptation, to take the wealth of knowledge that has been used to detect political bias in news content, and apply this to detecting political bias in social media content. 

-----------------------------------------


Regardless, there is a global appetite for unbiased news: a Pew Research survey across 38 countries found that 75\% of the public said it isn't acceptable for a news organisation to favour one political party \cite{pew-unbiased}, although only 52\% thought that their own country's news media report different positions on political issues fairly.

On top of this, social media usage has soared in the last decade \cite{rise-of-social-media}. Almost 70\% of Americans get their news from social media \cite{pew-social-media-news-2018}, and Facebook, Twitter and Reddit are the sites on which the highest proportion of users were exposed to news. The sheer volume of comments online 


Detecting political bias in the news is a key problem being tackled today, but a relevant side-problem is identifying \textit{readership bias} - the biases of those who read the news, and exploring how audiences react to modern media. Readership bias is a highly under-explored area in literature - it is hard to find any examples of people's reactions to particular news being analysed.


Improved political bias detection on social media will help us understand readership bias, and help us tackle further problems on social media such as filter bubbles and echo chambers.

Previous work has been done to manually detect political bias.

Work has already been done to manually classify news sources by political bias, such as by Media Bias/Fact Check \cite{mbfc} and Ad Fontes Media \cite{media-bias-chart}, however detecting any bias manually comes with several problems. Volunteers often need an education in political science and/or bias detection training before they can label biased text, and volunteers may also bring their own internal political bias to their labelling. We therefore consider applying machine learning and natural language processing techniques to these problems. Machine learning models only examine characteristics of the language itself, without any preconceived notions of politics or the current political atmosphere, and once trained a model can be quickly deployed for inference on any amount of new text, significantly speeding up the bias detection process.

Examining social media content for bias presents a different textual `domain' to news article text. We therefore aim to explore and extend state-of-the-art domain adaptation methods with the goal of improving bias detection on social media.

main objectives

 - survey existing methods for detecting political bias
 
 - explore transfer learning, specifically domain adaptation, as a way to improve accuracy of detecting readership bias on social media

\section{Contributions}

The main contributions of this dissertation are as follows:

\begin{itemize}
    \item \textbf{Detecting political bias with ensemble classifiers and BERT} - We survey existing machine learning models for detecting political bias, including ensemble classifiers that have not been explored in prior literature. We assess performance using pre-computed features from previous research, as well as using models such as BERT that perform textual feature extraction themselves. See Chapter \ref{chap:ensemble-bert}.
    \item \textbf{Developing a cross-domain Reddit dataset} - We create a novel dataset consisting of both news articles and Reddit comments that address those articles, aimed at domain adaptation tasks. We discuss the design decisions and trade-offs involved in creating a high-quality dataset, and assess similarity between the domains in our dataset. See Chapter \ref{chap:reddit-data}.
    \item \textbf{Exploring and extending unsupervised domain adaptation} - We investigate unsupervised domain adaptation to detect political bias on Reddit, and extend a state-of-the-art domain-adaptive BERT model, yielding a 3\% increase in accuracy on this task. See Chapter \ref{chap:domain-adaptation}.
\end{itemize}
